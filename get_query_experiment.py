import os
import torch
import json
import csv
import chromadb
from chromadb.config import Settings
from transformers import AutoTokenizer, AutoModel
import datetime

# ëª¨ë¸ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("BAAI/bge-m3")
model = AutoModel.from_pretrained("BAAI/bge-m3")
model.eval()

# ìƒˆ í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë°©ì‹
chroma_client = chromadb.PersistentClient(path="./chroma_db")

collection = chroma_client.get_or_create_collection(name="my_chunks")


# í•¨ìˆ˜: CLS í† í° ë²¡í„° ì¶”ì¶œ
def get_embedding(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        embedding = outputs.last_hidden_state[:, 0, :]
    return embedding.squeeze().tolist()

def search_chunks(query_text, top_k=3):
    # ì¿¼ë¦¬ ë¬¸ì¥ ì„ë² ë”© (BGE ìŠ¤íƒ€ì¼: Instruction ì¶”ê°€)
    query_embedding = get_embedding("Represent this sentence for retrieval: " + query_text)

    # ChromaDBì—ì„œ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ” '{query_text}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ (Top {top_k}):\n")
    if results and results['ids'] and results['documents'] and results['metadatas']:
        for i in range(len(results['ids'][0])):
            print(f"[{i+1}] ë¬¸ì„œ ID: {results['ids'][0][i]}")
            print(f"íŒŒì¼ëª…: {results['metadatas'][0][i]['filename']}")
            print(f"ë‚´ìš©: {results['documents'][0][i][:150]}...")  # ì²˜ìŒ 150ìë§Œ ì¶œë ¥
            print("-" * 60)
    else:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return results  # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •


def save_results_to_json(results, query_text, filename="search_results.json"):
    output = {
        "query": query_text,
        "results": []
    }

    if results and results['ids'] and results['documents'] and results['metadatas']:
        for i in range(len(results['ids'][0])):
            output["results"].append({
                "rank": i + 1,
                "id": results['ids'][0][i],
                "filename": results['metadatas'][0][i]['filename'],
                "document": results['documents'][0][i]
            })

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = f"./results/{filename.replace('.json', '')}_{timestamp}.json"

        os.makedirs("results", exist_ok=True)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"âœ… JSON í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")
    else:
        print("âš ï¸ ì €ì¥í•  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

def save_results_to_csv(results, query_text, filename="search_results.csv"):
    if not results or not results['ids'] or not results['documents'] or not results['metadatas']:
        print("âš ï¸ ì €ì¥í•  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filepath = f"./results/{filename.replace('.csv', '')}_{timestamp}.csv"

    os.makedirs("results", exist_ok=True)
    with open(filepath, "w", encoding="utf-8", newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["ìˆœìœ„", "ë¬¸ì„œ ID", "íŒŒì¼ëª…", "ë‚´ìš©"])
        
        for i in range(len(results['ids'][0])):
            writer.writerow([
                i + 1,
                results['ids'][0][i],
                results['metadatas'][0][i]['filename'],
                results['documents'][0][i]
            ])

    print(f"âœ… CSV í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

def save_results_to_txt(results, query_text, filename="search_results.txt"):
    if not results or not results['ids'] or not results['documents'] or not results['metadatas']:
        print("âš ï¸ ì €ì¥í•  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filepath = f"./results/{filename.replace('.txt', '')}_{timestamp}.txt"

    os.makedirs("results", exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query_text}\n\n")
        
        for i in range(len(results['ids'][0])):
            f.write(f"ìˆœìœ„: {i+1}\n")
            f.write(f"ë¬¸ì„œ ID: {results['ids'][0][i]}\n")
            f.write(f"íŒŒì¼ëª…: {results['metadatas'][0][i]['filename']}\n")
            f.write(f"ë‚´ìš©: {results['documents'][0][i]}\n")
            f.write("-" * 60 + "\n")

    print(f"âœ… TXT í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

def save_results_to_markdown(results, query_text, filename="search_results.md"):
    if not results or not results['ids'] or not results['documents'] or not results['metadatas']:
        print("âš ï¸ ì €ì¥í•  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filepath = f"./results/{filename.replace('.md', '')}_{timestamp}.md"

    os.makedirs("results", exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(f"# ê²€ìƒ‰ ê²°ê³¼\n\n")
        f.write(f"**ê²€ìƒ‰ ì¿¼ë¦¬**: {query_text}\n\n")
        
        for i in range(len(results['ids'][0])):
            f.write(f"## {i+1}ë²ˆì§¸ ê²°ê³¼\n")
            f.write(f"- **ë¬¸ì„œ ID**: {results['ids'][0][i]}\n")
            f.write(f"- **íŒŒì¼ëª…**: {results['metadatas'][0][i]['filename']}\n")
            f.write(f"- **ë‚´ìš©**:\n\n")
            f.write(f"```\n{results['documents'][0][i]}\n```\n\n")
            f.write("---\n\n")

    print(f"âœ… Markdown í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

def save_results(results, query_text, format="all"):
    """ëª¨ë“  í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    if format == "all" or format == "json":
        save_results_to_json(results, query_text)
    if format == "all" or format == "csv":
        save_results_to_csv(results, query_text)
    if format == "all" or format == "txt":
        save_results_to_txt(results, query_text)
    if format == "all" or format == "md":
        save_results_to_markdown(results, query_text)

# ì‚¬ìš© ì˜ˆì‹œ
query = "ì²­ì•½ ì‹ ì²­ ìê²© ì•Œë ¤ì¤˜"
search_results = search_chunks(query, top_k=5)
save_results(search_results, query, format="all")  # ëª¨ë“  í˜•ì‹ìœ¼ë¡œ ì €ì¥
# ë˜ëŠ” íŠ¹ì • í˜•ì‹ë§Œ ì €ì¥
# save_results(search_results, query, format="json")  # JSONë§Œ ì €ì¥
# save_results(search_results, query, format="csv")   # CSVë§Œ ì €ì¥
# save_results(search_results, query, format="txt")   # TXTë§Œ ì €ì¥
# save_results(search_results, query, format="md")    # Markdownë§Œ ì €ì¥