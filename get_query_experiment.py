import os
import torch
import json
import csv
import chromadb
from chromadb.config import Settings
from transformers import AutoTokenizer, AutoModel
import datetime
import re

# ëª¨ë¸ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("BAAI/bge-m3")
model = AutoModel.from_pretrained("BAAI/bge-m3")
model.eval()

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_or_create_collection(name="processed_chunks")

def get_embedding(text):
    """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        embedding = outputs.last_hidden_state[:, 0, :]
    return embedding.squeeze().tolist()

def search_chunks(query_text, top_k=3, pdf_name=None):
    """ì²­í¬ ê²€ìƒ‰ í•¨ìˆ˜"""
    query_embedding = get_embedding("Represent this sentence for retrieval: " + query_text)
    
    # PDF íŒŒì¼ëª…ì´ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ íŒŒì¼ ë‚´ì—ì„œë§Œ ê²€ìƒ‰
    if pdf_name:
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where={"filename": pdf_name}
        )
    else:
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

    print(f"\nğŸ” '{query_text}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ (Top {top_k}):")
    if results and results['ids'] and results['documents'] and results['metadatas']:
        for i in range(len(results['ids'][0])):
            metadata = results['metadatas'][0][i]
            content = results['documents'][0][i]
            
            print(f"\n[{i+1}] ë¬¸ì„œ: {metadata['filename']}")
            print(f"ì„¹ì…˜: {metadata.get('title', 'ì œëª© ì—†ìŒ')}")
            
            # ë‚´ìš© ì¶œë ¥ (ì œëª© íƒœê·¸ ì œê±°)
            content_without_title = re.sub(r'<h\d>.*?</h\d>\n?', '', content, 1)
            print(f"ë‚´ìš©: {content_without_title[:200]}...")  # ì²˜ìŒ 200ìë§Œ ì¶œë ¥
            print("-" * 80)
    else:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return results

def get_pdf_list():
    """ì €ì¥ëœ ëª¨ë“  PDF íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    results = collection.get()
    if results and results['metadatas']:
        pdf_files = sorted(set(meta['filename'] for meta in results['metadatas']))
        print("\nğŸ“š ì €ì¥ëœ PDF íŒŒì¼ ëª©ë¡:")
        for i, pdf in enumerate(pdf_files, 1):
            print(f"{i}. {pdf}")
        return pdf_files
    return []

def get_pdf_sections(pdf_name):
    """íŠ¹ì • PDFì˜ ì„¹ì…˜ ëª©ë¡ ì¡°íšŒ"""
    results = collection.get(
        where={"filename": pdf_name}
    )
    
    if results and results['metadatas']:
        sections = sorted(set(meta.get('title', 'ì œëª© ì—†ìŒ') for meta in results['metadatas']))
        print(f"\nğŸ“‘ {pdf_name} ì„¹ì…˜ ëª©ë¡:")
        for i, section in enumerate(sections, 1):
            print(f"{i}. {section}")
        return sections
    return []

def get_pdf_content(pdf_name, section_title=None):
    """PDF ë‚´ìš© ì¡°íšŒ (ì „ì²´ ë˜ëŠ” íŠ¹ì • ì„¹ì…˜)"""
    where_clause = {"filename": pdf_name}
    if section_title:
        where_clause["title"] = section_title
    
    results = collection.get(where=where_clause)
    
    if not results or not results['metadatas']:
        print(f"âŒ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì²­í¬ ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    chunks = list(zip(results['metadatas'], results['documents']))
    chunks.sort(key=lambda x: x[0].get('chunk_index', 0))
    
    print(f"\nğŸ“„ {pdf_name}")
    if section_title:
        print(f"ì„¹ì…˜: {section_title}")
    print("=" * 80)
    
    for metadata, content in chunks:
        title = metadata.get('title', 'ì œëª© ì—†ìŒ')
        if not section_title:  # ì „ì²´ ë‚´ìš© ì¡°íšŒì‹œ ì„¹ì…˜ ì œëª© í‘œì‹œ
            print(f"\n## {title}")
        content_without_title = re.sub(r'<h\d>.*?</h\d>\n?', '', content, 1)
        print(content_without_title.strip())
        print("-" * 80)
    
    return chunks

def save_results_to_json(results, query_text, filename="search_results.json"):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    output = {
        "query": query_text,
        "results": []
    }

    if results and results['ids'] and results['documents'] and results['metadatas']:
        for i in range(len(results['ids'][0])):
            metadata = results['metadatas'][0][i]
            output["results"].append({
                "rank": i + 1,
                "id": results['ids'][0][i],
                "filename": metadata['filename'],
                "section": metadata.get('title', 'ì œëª© ì—†ìŒ'),
                "document": results['documents'][0][i]
            })

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = f"./results/{filename.replace('.json', '')}_{timestamp}.json"

        os.makedirs("results", exist_ok=True)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"âœ… ê²€ìƒ‰ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")
    else:
        print("âš ï¸ ì €ì¥í•  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

def save_pdf_content(pdf_name, output_format="txt", section_title=None):
    """PDF ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥"""
    content = get_pdf_content(pdf_name, section_title)
    if not content:
        return
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    section_suffix = f"_{section_title}" if section_title else ""
    filename = f"{pdf_name}_{timestamp}{section_suffix}.{output_format}"
    filepath = os.path.join("results", filename)
    
    os.makedirs("results", exist_ok=True)
    
    with open(filepath, "w", encoding="utf-8") as f:
        if output_format == "txt":
            for metadata, doc in content:
                title = metadata.get('title', 'ì œëª© ì—†ìŒ')
                f.write(f"\n## {title}\n")
                content_without_title = re.sub(r'<h\d>.*?</h\d>\n?', '', doc, 1)
                f.write(content_without_title.strip() + "\n\n")
                f.write("-" * 80 + "\n")
        elif output_format == "json":
            json.dump({
                "filename": pdf_name,
                "section": section_title,
                "content": [{
                    "title": meta.get('title', 'ì œëª© ì—†ìŒ'),
                    "text": re.sub(r'<h\d>.*?</h\d>\n?', '', doc, 1).strip()
                } for meta, doc in content]
            }, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

def check_eligibility(user_info):
    """ì‚¬ìš©ì ì§€ì› ìê²© ê²€ì¦"""
    # ê²€ìƒ‰í•  í‚¤ì›Œë“œ êµ¬ì„±
    search_queries = [
        "ì§€ì›ìê²©",
        "ì‹ ì²­ìê²©",
        "ìê²©ìš”ê±´",
        "ì†Œë“ê¸°ì¤€",
        "ìì‚°ê¸°ì¤€",
        "ì—°ë ¹ì œí•œ",
        "ë‚˜ì´ì œí•œ",
        "ìë™ì°¨ë³´ìœ ",
        "ì°¨ëŸ‰ë³´ìœ ",
        "ì¬í•™ìƒ",
        "ì¡¸ì—…ìƒ",
        "ì·¨ì—…ì—¬ë¶€",
        "ìˆ˜ê¸‰ì",
        "ì¥ì• ì¸"
    ]
    
    # ëª¨ë“  PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    pdf_files = get_pdf_list()
    eligibility_results = []
    
    for pdf_name in pdf_files:
        pdf_result = {
            "pdf_name": pdf_name,
            "eligible": True,
            "requirements": [],
            "matched_conditions": [],
            "unmet_conditions": []
        }
        
        # ê° ê²€ìƒ‰ í‚¤ì›Œë“œì— ëŒ€í•´ í•´ë‹¹ PDFì˜ ìê²© ì¡°ê±´ ê²€ìƒ‰
        for query in search_queries:
            results = search_chunks(query, top_k=3, pdf_name=pdf_name)
            if results and results['documents']:
                for doc in results['documents'][0]:
                    requirement = analyze_requirement(doc, user_info)
                    if requirement:
                        pdf_result["requirements"].extend(requirement)
        
        # ìê²© ìš”ê±´ ë¶„ì„ ê²°ê³¼ ì •ë¦¬
        pdf_result = analyze_eligibility(pdf_result, user_info)
        eligibility_results.append(pdf_result)
    
    return eligibility_results

def analyze_requirement(text, user_info):
    """í…ìŠ¤íŠ¸ì—ì„œ ìê²© ìš”ê±´ ì¶”ì¶œ ë° ë¶„ì„"""
    requirements = []
    
    # ë‚˜ì´/ì—°ë ¹ ì œí•œ í™•ì¸
    birth_year = int(user_info["birth_date"][:4])
    current_year = datetime.datetime.now().year
    age = current_year - birth_year + 1  # í•œêµ­ ë‚˜ì´
    
    age_patterns = [
        r'(\d+)ì„¸\s*(?:ë¯¸ë§Œ|ì´í•˜|ì´ìƒ|ì´ˆê³¼)',
        r'ë§Œ\s*(\d+)ì„¸\s*(?:ë¯¸ë§Œ|ì´í•˜|ì´ìƒ|ì´ˆê³¼)',
        r'(\d+)ë…„ìƒ\s*(?:ì´í›„|ì´ì „)'
    ]
    
    for pattern in age_patterns:
        matches = re.finditer(pattern, text)
        for match in matches:
            requirements.append({
                "type": "age",
                "text": match.group(0),
                "value": int(match.group(1))
            })
    
    # ì†Œë“ ê¸°ì¤€ í™•ì¸
    income_patterns = [
        r'ì†Œë“\s*(\d+)%\s*ì´í•˜',
        r'í‰ê· \s*ì†Œë“\s*(\d+)%\s*ì´í•˜',
        r'ì†Œë“ê¸°ì¤€\s*(\d+)%\s*ì´í•˜'
    ]
    
    for pattern in income_patterns:
        matches = re.finditer(pattern, text)
        for match in matches:
            requirements.append({
                "type": "income",
                "text": match.group(0),
                "value": int(match.group(1))
            })
    
    # ìì‚° ê¸°ì¤€ í™•ì¸
    asset_patterns = [
        r'ì´ìì‚°\s*(\d+)(?:ë§Œì›|ì–µì›)',
        r'ìì‚°\s*(\d+)(?:ë§Œì›|ì–µì›)'
    ]
    
    for pattern in asset_patterns:
        matches = re.finditer(pattern, text)
        for match in matches:
            requirements.append({
                "type": "assets",
                "text": match.group(0),
                "value": convert_to_won(match.group(1), match.group(0))
            })
    
    # ì°¨ëŸ‰ ê¸°ì¤€ í™•ì¸
    if "ì°¨ëŸ‰" in text or "ìë™ì°¨" in text:
        requirements.append({
            "type": "car",
            "text": text,
            "value": None
        })
    
    # ìˆ˜ê¸‰ì ê´€ë ¨ í™•ì¸
    if "ìˆ˜ê¸‰ì" in text:
        requirements.append({
            "type": "welfare",
            "text": text,
            "value": None
        })
    
    return requirements

def analyze_eligibility(pdf_result, user_info):
    """ìê²© ìš”ê±´ê³¼ ì‚¬ìš©ì ì •ë³´ ë¹„êµ ë¶„ì„"""
    for req in pdf_result["requirements"]:
        if req["type"] == "age":
            birth_year = int(user_info["birth_date"][:4])
            current_year = datetime.datetime.now().year
            age = current_year - birth_year + 1
            
            if "ì´í•˜" in req["text"] and age > req["value"]:
                pdf_result["eligible"] = False
                pdf_result["unmet_conditions"].append(f"ë‚˜ì´ ì œí•œ: {req['text']}")
            elif "ì´ìƒ" in req["text"] and age < req["value"]:
                pdf_result["eligible"] = False
                pdf_result["unmet_conditions"].append(f"ë‚˜ì´ ì œí•œ: {req['text']}")
            else:
                pdf_result["matched_conditions"].append(f"ë‚˜ì´ ì¡°ê±´ ì¶©ì¡±: {age}ì„¸")
        
        elif req["type"] == "income":
            user_income = int(user_info["income_range"].replace("% ì´í•˜", ""))
            if user_income > req["value"]:
                pdf_result["eligible"] = False
                pdf_result["unmet_conditions"].append(f"ì†Œë“ ê¸°ì¤€: {req['text']}")
            else:
                pdf_result["matched_conditions"].append(f"ì†Œë“ ê¸°ì¤€ ì¶©ì¡±: {user_income}%")
        
        elif req["type"] == "assets":
            if int(user_info["total_assets"]) > req["value"]:
                pdf_result["eligible"] = False
                pdf_result["unmet_conditions"].append(f"ìì‚° ê¸°ì¤€: {req['text']}")
            else:
                pdf_result["matched_conditions"].append("ìì‚° ê¸°ì¤€ ì¶©ì¡±")
        
        elif req["type"] == "car":
            if int(user_info["car_value"]) > 0:
                pdf_result["eligible"] = False
                pdf_result["unmet_conditions"].append("ì°¨ëŸ‰ ë³´ìœ  ì œí•œ")
            else:
                pdf_result["matched_conditions"].append("ì°¨ëŸ‰ ê¸°ì¤€ ì¶©ì¡±")
    
    return pdf_result

def convert_to_won(value, unit):
    """ê¸ˆì•¡ ë‹¨ìœ„ ë³€í™˜"""
    value = int(value)
    if "ì–µì›" in unit:
        return value * 100000000
    elif "ë§Œì›" in unit:
        return value * 10000
    return value

def get_eligible_programs(user_info):
    """ì‚¬ìš©ìê°€ ì§€ì› ê°€ëŠ¥í•œ í”„ë¡œê·¸ë¨ ëª©ë¡ ì¡°íšŒ"""
    results = check_eligibility(user_info)
    
    eligible_programs = []
    ineligible_programs = []
    
    for result in results:
        program_info = {
            "name": result["pdf_name"],
            "matched_conditions": result["matched_conditions"],
            "unmet_conditions": result["unmet_conditions"]
        }
        
        if result["eligible"]:
            eligible_programs.append(program_info)
        else:
            ineligible_programs.append(program_info)
    
    return {
        "eligible": eligible_programs,
        "ineligible": ineligible_programs
    }

def check_eligibility_for_specific_notice(pdf_name, user_info):
    """íŠ¹ì • ê³µê³ ë¬¸ì— ëŒ€í•œ ì‚¬ìš©ì ì§€ì› ìê²© ê²€ì¦"""
    
    # ìê²© ê´€ë ¨ ì„¹ì…˜ ê²€ìƒ‰
    eligibility_keywords = [
        "ì§€ì›ìê²©",
        "ì‹ ì²­ìê²©",
        "ì…ì£¼ìê²©",
        "ìê²©ìš”ê±´",
        "ì‹ ì²­ëŒ€ìƒ"
    ]
    
    eligibility_sections = []
    for keyword in eligibility_keywords:
        results = search_chunks(keyword, top_k=5, pdf_name=pdf_name)
        if results and results['documents'] and results['documents'][0]:
            eligibility_sections.extend(results['documents'][0])
    
    # ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    analysis_result = {
        "pdf_name": pdf_name,
        "eligible": True,
        "matched_conditions": [],
        "unmet_conditions": [],
        "eligibility_details": {}
    }
    
    # ì—°ë ¹ ì¡°ê±´ í™•ì¸
    birth_year = int(user_info["birth_date"][:4])
    current_year = datetime.datetime.now().year
    age = current_year - birth_year + 1  # í•œêµ­ ë‚˜ì´
    
    # ê° ìê²© ì¡°ê±´ í™•ì¸
    for section in eligibility_sections:
        # 1. ì—°ë ¹ ì œí•œ í™•ì¸
        age_patterns = [
            r'(?:ë§Œ\s*)?(\d+)ì„¸\s*(?:ë¯¸ë§Œ|ì´í•˜|ì´ìƒ|ì´ˆê³¼)',
            r'(?:ë§Œ\s*)?(\d+)ì„¸ë¶€í„°\s*(?:ë§Œ\s*)?(\d+)ì„¸ê¹Œì§€',
            r'(\d+)ë…„(?:ìƒ|ë„)\s*(?:ì´í›„|ì´ì „)'
        ]
        
        for pattern in age_patterns:
            matches = re.finditer(pattern, section)
            for match in matches:
                age_text = match.group(0)
                if "ì´í•˜" in age_text or "ë¯¸ë§Œ" in age_text:
                    age_limit = int(match.group(1))
                    if age > age_limit:
                        analysis_result["eligible"] = False
                        analysis_result["unmet_conditions"].append(f"ì—°ë ¹ ì¡°ê±´: {age_text} (í˜„ì¬ {age}ì„¸)")
                    else:
                        analysis_result["matched_conditions"].append(f"ì—°ë ¹ ì¡°ê±´ ì¶©ì¡±: {age}ì„¸")
                elif "ì´ìƒ" in age_text or "ì´ˆê³¼" in age_text:
                    age_limit = int(match.group(1))
                    if age < age_limit:
                        analysis_result["eligible"] = False
                        analysis_result["unmet_conditions"].append(f"ì—°ë ¹ ì¡°ê±´: {age_text} (í˜„ì¬ {age}ì„¸)")
                    else:
                        analysis_result["matched_conditions"].append(f"ì—°ë ¹ ì¡°ê±´ ì¶©ì¡±: {age}ì„¸")
        
        # 2. ì†Œë“ ê¸°ì¤€ í™•ì¸
        income_patterns = [
            r'(?:ì†Œë“|ì†Œë“ê¸°ì¤€|í‰ê· ì†Œë“)\s*(\d+)%\s*(?:ì´í•˜|ë¯¸ë§Œ)',
            r'(?:ì†Œë“|ì†Œë“ê¸°ì¤€|í‰ê· ì†Œë“)\s*(\d+)%\s*ì´ˆê³¼'
        ]
        
        user_income = int(user_info["income_range"].replace("% ì´í•˜", ""))
        for pattern in income_patterns:
            matches = re.finditer(pattern, section)
            for match in matches:
                income_text = match.group(0)
                income_limit = int(match.group(1))
                if "ì´í•˜" in income_text or "ë¯¸ë§Œ" in income_text:
                    if user_income > income_limit:
                        analysis_result["eligible"] = False
                        analysis_result["unmet_conditions"].append(f"ì†Œë“ ê¸°ì¤€: {income_text}")
                    else:
                        analysis_result["matched_conditions"].append(f"ì†Œë“ ê¸°ì¤€ ì¶©ì¡±: {user_income}%")
        
        # 3. ìì‚° ê¸°ì¤€ í™•ì¸
        asset_patterns = [
            r'(?:ì´ìì‚°|ìì‚°)\s*(\d+)(?:ë§Œì›|ì–µì›)\s*(?:ì´í•˜|ë¯¸ë§Œ)',
            r'(?:ì´ìì‚°|ìì‚°)\s*(\d+)(?:ë§Œì›|ì–µì›)\s*ì´ˆê³¼'
        ]
        
        for pattern in asset_patterns:
            matches = re.finditer(pattern, section)
            for match in matches:
                asset_text = match.group(0)
                asset_value = convert_to_won(match.group(1), asset_text)
                if int(user_info["total_assets"]) > asset_value:
                    analysis_result["eligible"] = False
                    analysis_result["unmet_conditions"].append(f"ìì‚° ê¸°ì¤€: {asset_text}")
                else:
                    analysis_result["matched_conditions"].append("ìì‚° ê¸°ì¤€ ì¶©ì¡±")
        
        # 4. ì°¨ëŸ‰ ë³´ìœ  ê¸°ì¤€ í™•ì¸
        if "ì°¨ëŸ‰" in section or "ìë™ì°¨" in section:
            car_value = int(user_info["car_value"])
            if car_value > 0:
                analysis_result["eligible"] = False
                analysis_result["unmet_conditions"].append("ì°¨ëŸ‰ ë³´ìœ  ì œí•œ")
            else:
                analysis_result["matched_conditions"].append("ì°¨ëŸ‰ ê¸°ì¤€ ì¶©ì¡±")
        
        # 5. ìˆ˜ê¸‰ì ê´€ë ¨ í™•ì¸
        if "ìˆ˜ê¸‰ì" in section and user_info["household_type"] == "ìƒê³„Â·ì˜ë£ŒÂ·ì£¼ê±°ê¸‰ì—¬ ìˆ˜ê¸‰ì ê°€êµ¬":
            analysis_result["matched_conditions"].append("ìˆ˜ê¸‰ì ê°€êµ¬ ì¡°ê±´ ì¶©ì¡±")
        
        # 6. ëŒ€í•™ìƒ ê´€ë ¨ í™•ì¸
        if "ëŒ€í•™ìƒ" in section or "ì¬í•™" in section:
            if user_info["university_status"] == "ì¬í•™ ì¤‘":
                analysis_result["matched_conditions"].append("ëŒ€í•™ìƒ ì¡°ê±´ ì¶©ì¡±")
            else:
                analysis_result["unmet_conditions"].append("ëŒ€í•™ìƒ(ì¬í•™ìƒ) ì¡°ê±´ ë¯¸ì¶©ì¡±")
    
    # ê²€ì¦ ê²°ê³¼ ìš”ì•½
    analysis_result["eligibility_details"] = {
        "total_conditions": len(analysis_result["matched_conditions"]) + len(analysis_result["unmet_conditions"]),
        "matched_count": len(analysis_result["matched_conditions"]),
        "unmet_count": len(analysis_result["unmet_conditions"])
    }
    
    return analysis_result

def print_eligibility_result(result):
    """ìê²© ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f"ğŸ“‹ ê³µê³ ë¬¸: {result['pdf_name']}")
    print("=" * 80)
    
    if result["eligible"]:
        print("\nâœ… ì§€ì› ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    else:
        print("\nâŒ ì§€ì› ìê²©ì´ ì¶©ì¡±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    print("\n[ì¶©ì¡±ëœ ì¡°ê±´]")
    for condition in result["matched_conditions"]:
        print(f"âœ“ {condition}")
    
    if result["unmet_conditions"]:
        print("\n[ë¯¸ì¶©ì¡±ëœ ì¡°ê±´]")
        for condition in result["unmet_conditions"]:
            print(f"âœ— {condition}")
    
    print("\n[ê²€ì¦ ê²°ê³¼ ìš”ì•½]")
    print(f"- ì „ì²´ ì¡°ê±´ ìˆ˜: {result['eligibility_details']['total_conditions']}")
    print(f"- ì¶©ì¡±ëœ ì¡°ê±´ ìˆ˜: {result['eligibility_details']['matched_count']}")
    print(f"- ë¯¸ì¶©ì¡±ëœ ì¡°ê±´ ìˆ˜: {result['eligibility_details']['unmet_count']}")
    print("=" * 80)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì‚¬ìš©ì ì •ë³´
    user_info = {
        "birth_date": "990101",
        "gender": "ë‚¨ì„±",
        "university_status": "ì¬í•™ ì¤‘",
        "recent_graduate": "ì˜ˆ",
        "employed": "ì•„ë‹ˆì˜¤",
        "job_seeking": "ì•„ë‹ˆì˜¤",
        "household_type": "ìƒê³„Â·ì˜ë£ŒÂ·ì£¼ê±°ê¸‰ì—¬ ìˆ˜ê¸‰ì ê°€êµ¬",
        "parents_own_house": "ì•„ë‹ˆìš”",
        "disability_in_family": "ì˜ˆ",
        "application_count": 2,
        "total_assets": 1000000,
        "car_value": 500000,
        "income_range": "100% ì´í•˜"
    }
    
    # íŠ¹ì • ê³µê³ ë¬¸ ì„ íƒ
    pdf_name = "[ë§ˆì„ê³¼ì§‘]SHíŠ¹í™”í˜• ë§¤ì…ì„ëŒ€ì£¼íƒ(ì²­ë…„) ì…ì£¼ì ëª¨ì§‘ ê³µê³ ë¬¸_20250307.pdf"
    
    # ìê²© ê²€ì¦
    result = check_eligibility_for_specific_notice(pdf_name, user_info)
    
    # ê²°ê³¼ ì¶œë ¥
    print_eligibility_result(result)